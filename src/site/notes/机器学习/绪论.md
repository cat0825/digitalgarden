---
{"dg-publish":true,"dg-permalink":"\"机器学习/绪论\"","permalink":"/\"机器学习/绪论\"/","dgPassFrontmatter":true,"created":"2024-01-28T23:03:21.601+08:00","updated":"2024-06-25T22:13:45.288+08:00"}
---

## 引言
机器学习就像是在教计算机从经验中学习，这里的经验是什么呢，经验在计算机中以数据的形式存储，那我们要学习什么呢，要让计算机从过往的经验中学习，通过分析数据来学习规律和模式，然后利用这些知识来做出预测和决策。因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生“模 型 "（model）的算法，即 “学习算法”（learning algorithm）.有了学习算法，我 们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时（例如看到一个没剖开的西瓜），模型会给我们提供相应的判断（例如好瓜）

举几个例子来说明机器学习的用途：

1. **个性化推荐**：比如Netflix推荐你可能喜欢的电影，或者Spotify推荐你可能喜欢的音乐。
2. **语音识别**：像Siri或Google Assistant那样，它们可以理解你的话，并给出回答。
3. **医疗诊断**：帮助医生分析影像数据，比如X光片或MRI，从而更快地诊断出病症。
4. **自动驾驶车辆**：让汽车能够理解周围的环境并安全驾驶。

$\left(\boldsymbol{x}_i,y_i\right)\text{表示第 }i\text{ 个样例}$ 其中x是对样本的描述，y是样本的标签也可以叫做“结果”
若我们欲预测的是**离散值**，例 如 “好瓜” “坏瓜”，此类学习任务称为 “**分类** "(classification);若欲预测的是**连续值**，例如西瓜成熟度0.95、0.37,此类学习任务称为“**回归**”(reg ression ).对只涉及两个类别的“二分 类" (binary classifcation)任务，通常称其中一个类为“正类”(positive class), 另一个类为“反类”(negative c la ss );涉及多个类别时，则 称 为 多分类(multi-class classification)任务，$\begin{aligned}&\text{类”(multi-class classification) 任务.一般地,预测任务是希望通过对训练}\\&\text{集 }\left\{(x_1,y_1),(x_2,y_2),\ldots,(x_m,y_m)\right\}\text{进行学习},\text{建立一个从输入空间 }\mathcal{X}\text{ 到输出}\\&\text{空间 }\mathcal{Y}\text{ 的映射 }f:\mathcal{X}\mapsto\mathcal{Y}.\text{ 对二分类任务,通常令 }\mathcal{Y}=\{-1,+1\}\text{ 或 }\{0,1\};\text{ 对}\\&\text{多分类任务, }|\mathcal{Y}|>2;\text{ 对回归任务 },\mathcal{Y}=\mathbb{R},\mathbb{R}\text{ 为实数集}.\end{aligned}$

---
我们根据训练数据是否有标记信息，将学习任务大致划分为两大块类，监督学习和无监督学习，分类和回归是前者的代表,而聚类则是后者的代表。
泛化功能指的是，学得模型适用于新样本的能力

---
我们把学习过程看做一个在所有假设组成的空间中进行搜索的过程，所售目标是找到和训练集匹配的假设，在其中可能会出现以下情况：
想象一下你在一家餐厅里点餐，但菜单上有成千上万道菜。如果你没有任何偏好，选择一道菜可能会非常困难，因为可能性太多了。但如果你偏爱素食或者喜欢意大利菜，这个偏好可以帮你快速缩小选择范围，并在合理的时间内做出决定。

在机器学习中，归纳偏好的作用类似于在选择菜单上的一道菜时的个人偏好。当一个算法尝试从数据中学习并做出预测时，通常会有许多可能的模型或“假设”可供选择。归纳偏好帮助算法：

1. **缩小选择范围**：
    
    - 就像个人偏好帮你从成千上万道菜中选择，归纳偏好帮助算法从可能的模型中做出选择。
2. **解决过拟合问题**：
    
    - 如果没有任何偏好，算法可能会选择过于复杂的模型，这些模型在训练数据上表现得很好，但在新数据上表现不佳（这称为过拟合）。归纳偏好鼓励算法选择更简单、更普适的模型。
3. **指导学习过程**：
    
    - 在面对不确定性或数据不足时，归纳偏好提供了额外的信息，可以帮助算法做出更合理的预测。
4. **提高效率**：
    
    - 通过减少模型搜索空间，归纳偏好可以使学习过程更加高效。

总之，归纳偏好就像是给机器学习算法的一个指南针，帮助它在海量的可能性中找到合适、有效且可靠的解决方案。
**像是学习算法自己的一个价值观一样**

---
没有免费的午餐”定理（No Free Lunch Theorem,简称NFL定理）[Wolpert, 1996; Wolpert and Macready, 1995].

脱离具体问题，空谈什么学习算法更好是没有意义的，若考虑所有潜在的问题，那么所有学习算法都是一样好的，要讨论学习算法的相对优劣，必须针对具体的学习问题。

---
绪论done 可能以后会补充喵~